skripte/python
==============

Vorwort
=======

Selbstdokumentierende Python-Module, Hilfsdateien und experimentelle Skripte
zur Arbeit mit der Wortliste.

Siehe Abschnitt `Arbeitsfluss`_ für einen Vorschlag zur Anwendung.

Das Programm PyLit_ kann die ausführbaren Dateien ``*.py`` reversibel in
Textdokumente ``*.py.txt`` konvertieren. Mit Docutils_ lassen sich aus den
in reStructuredText_ geschriebenen Texten Dokumentationen im HTML- oder
PDF-Format erstellen.

.. _PyLit: http://pylit.berlios.de
.. _reStructuredText: http://docutils.sourceforge.net/rst.html
.. _Docutils: http://docutils.sourceforge.net/rst.html


Unterverzeichnisse
==================

patuse/
-------

Anwendungen der mit `patgen` generierten Pattern.

hyphenation.py
  Hyphenation using a pure Python implementation of Frank Liang's algorithm.

  This module provides a class to hyphenate words.
  Verwendet in hyphenate_neueintraege.py

  Command-line usage: ``./hyphenation.py [options] [words to be hyphenated]``

long_s_conversion.py
  Rund-S nach Lang-S Wandlung über "hyphenation patterns".

  Aufruf: siehe ``./long_s_conversion.py -h``


edit_tools
----------

wortliste.py
  Python-Modul für die Arbeit mit der `Wortliste`.
  Wird von den anderen Python-Skripten importiert.

  Aufruf mit ``python wortliste.py`` startet einen
  Test der Werkzeuge und der inneren Konsistenz der Wortliste
  (Doppeleinträge, Übereinstimmung Schlüssel-Trennmuster).


Skripte zur Arbeit mit der Wortliste
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

(Trennstellenkategorisierung, Neueinträge, Korrekturen)

Siehe auch den Abschnitt `Arbeitsfluss`_ am Ende dieses Dokumentes.

.. Achtung:: Experimentell

  Die Skripte wurden für die eigene Arbeit mit der Wortliste entwickelt und
  erfordern zum Teil Anpassungen im Quelltext, eine gewisse Einarbeitung,
  Lesen der enthaltenen Dokumentation und gegebenenfalls Rücksprachen mit
  dem Autor.

* Die Skripte können ohne Schaden anzurichten probiert werden, denn sie
  ändern nicht direkt die Wortliste sondern erstellen eine Datei
  ``wortliste.patch``.

* Die Änderungen können nach Korrekturlesen mittels ::

    patch ../../wortliste < wortliste.patch

  auf die Wortliste angewendet werden.


abgleich_endungen.py
  Abgleich der Trennstellen für Ableitungen/Varianten mit unterschiedlicher
  Endung.

  Die zu vergleichenden Endungen sind im Skript in der Liste ``endungen``
  definiert.

abgleich_neueintraege.py
  Übertragen von Trennstellen aus (Teil-) Wörtern der "Wortliste"
  auf neu aufzunehmende, ungetrennte Wörter oder
  Einträge im Format der Wortliste (zum Test auf Mehrdeutigkeiten
  oder Fehler).
  
  Hilfe und Details mit ::
    
    python abgleich_neueintraege.py --help

  Die Ausgabe kann nach ``neu.todo`` gespeichert und (nach Durchsicht) mit
  ``prepare_patch.py neu`` in die Wortliste eingepflegt werden, z.B. ::

    python abgleich_neueintraege.py < neue-woerter.txt > todo.txt

abgleich_praefixe.py
  Abgleich der Trennstellen zwischen Wörtern mit unterschiedlichem Präfix

  Benötigt eine Liste der Teilwörter, die mit ``analyse.py`` erstellt werden
  kann (siehe Arbeitsfluss_).

abgleich_sprachvarianten.py
  Abgleich der Trennstellen zwischen Sprachvarianten

  Aufruf: ``python abgleich_sprachvarianten.py``

  * Übertragen von kategorisierten Trennstellen zwischen Sprachvarianten
    desselben Wortes, und/oder
  * Zusammenfassen von Feldern mit gleichem Inhalt wenn das Ergebnis ein
    wohlgeformter Eintrag ist.
  * Ergänzen von Formen mit SS statt ß.

abgleich_suffixe.py
  Abgleich der Trennstellen zwischen Wörtern mit unterschiedlichem Suffix.

  Benötigt eine Liste der Teilwörter, die mit ``analyse.py`` erstellt werden
  kann (siehe Arbeitsfluss_).


abgleich_teilwoerter.py
  Übertragen von kategorisierten Trennstellen von Teilwörtern auf
  Vorkommen dieser Teilwörter mit unkategorisierten Trennstellen.

  Aufruf: ``python abgleich_teilwoerter.py``

          Vorher in Zeile 26 ff. die gewünschte Sprachvariante
          durch ein/auskommentieren wählen.


analyse.py
  Sammeln und Sortieren von Teilwörtern

  Aufruf: ``python analyse.py``

          Vorher in Zeile 355 ff. die gewünschte Sprachvariante
          durch ein/auskommentieren wählen.

  Schreibt eine Liste der Teilwörter von in der Wortliste markierten
  zusammengesetzten Wörtern mit den Häufigkeiten des Auftretens
  in eine Datei ``teilwoerter-<Sprachtag>.txt``
  (z.B. ``teilwoerter-de-1901.txt``).

  Auf der Standardausgabe erscheint eine Zusammenfassung zum Stand der
  Präfixauszeichnung.

expand_teilwoerter.py
  Erweitern der Wortliste um Kombinationen von Teilwörtern

  Zerlegen von Composita an den Wortfugen und Übernahme der Teile als
  eigenständige Einträge.


hyphenate_neueintraege.py
  Versuche kategorisierte Trennung über "hyphenation"-Algorithmus und
  patgen-patterns.

  Verwendet Pattern-Dateien welche über die "make" Ziele
  `make pattern-refo`, `make major pattern-refo` und
  `make fugen pattern-refo` im Wurzelverzeichnis der Wortliste generiert
  werden können.

  Erwartet eine Datei mit 1 Wort/Zeile.
  Pfad/Dateiname im Abschnitt Konfiguration anpassen!

  Schreibt eine Liste auf stdout. Die Liste kann nach ``neu.todo``
  gespeichert und (nach Durchsicht) mit ``prepare_patch.py neu`` in die
  Wortliste eingepflegt werden.

prepare_patch.py
  Helfer für kleine Editieraufgaben, u.a. entfernen von Doppeleinträgen,
  Einsortieren neuer Einträge, Überschreiben mit korrigierten Einträgen, ...
  Erstellt eine Patch-Datei.

  Aufruf: siehe ``./prepare_patch.py -h``

test_teilwoerter.py
  Test der Markierung von Komposita in der Wortliste

teilwoerter_*.txt
  Liste der Teilwörter der Komposita in der `Wortliste`.
  Erstellt mit ``analyse.py`` durch Trennen an "=".
  Listet Häufigkeiten des Auftretens als:

  :S: Einzelwort (Solitär)
  :E: erstes Wort in Verbindungen
  :M: mittleres Wort in Verbindungen
  :L: letztes Wort in Verbindungen

  Format:

  * Teilwort mit Trennungen. Großschreibung wie Gesamtwort
  * Leerraum (whitespace)
  * Häufigkeiten in der Reihenfolge S;E;M;L

  Beispiel:

  Ho-se 1;0;0;7


vorsilben_in_teilwoertern.py
  Spezialwerkzeug zur Präfixmarkierung.

  Benötigt eine Liste der Teilwörter, die mit ``analyse.py`` erstellt werden
  kann.

wortfugen.py
  Suche nach "Teilwortkandidaten" in der Wortliste.

wortteile/
  Verzeichnis für Hilfsdateien (Daten/Text)


lang_s
------

Lang-s Schreibung

s2long-s.py
  Automatische Bestimmung der S-Schreibung auf Basis der Silbentrennung
  in der `Wortliste der deutschsprachigen Trennmustermannschaft`.

de_Latf_quasihyph.py
  Filter zum Wandeln von Wörtern mit Rund- und Lang-S in
  Pseudo-Trennbeispiele (ausſagen -> aus-sagen)."""

long_s_quasihyph.py
  Filter zum Wandeln von Wörtern mit langem S in
  Pseudo-Trennbeispiele (ausſagen -> auss-agen, eſſen -> es-s-en).


Arbeitsfluss
============

Trennstellenkategorisierung mit Hilfe der Python-Skripte,
2-stufiges Vorgehen:

* Erstellen einer Liste mit Teilwörtern (Zerlegung ausgezeichneter Komposita
  an den Wortfugen "="):

  - in `analyse.py` die gewünschte Sprachvariante ein-/auskommentieren.

  - ``python analyse.py``

  Die erstellte Wortliste ist ``teilwoerter-<Sprachtag>.txt``.

* Bearbeiten der generierten Datei

  - im Texteditor (suchen/ersetzen, regexp-replace, ...)

  - mit Skripten (``abgleich_praefixe.py``,
                  ``abgleich_suffixe.py``,
                  ``vorsilben_in_teilwoertern.py``)

* Rückübertragen der Korrekturen auf die Wortliste

  - in `abgleich_teilwoerter.py` die gewünschte Sprachvariante und
    Bearbeitungsfunktion ein-/auskommentieren.

  - ``python abgleich_teilwoerter.py``

  - Prüfen der Kontrollausgabe, ggf. Korrektur von ``wortliste.patch``.

  - ``patch ../../wortliste < wortliste.patch``


Trennung unbekannter Wörter (2 Alternativen):

* Mit `abgleich_neueintraege.py` versuchen, ob Trennstellen durch Vergleich
  mit vorhandenen Einträgen bestimmt werden können. Liefert Vorschläge für
  gewichtete, kategorisierte Einträge, die nach Durchsicht und Korrekturen
  mit prepare_patch.py eingepflegt werden können.

* Mit `hyphenate_neueintraege.py` Trennstellen durch Anwendung des
  TeX-Algorithmus bestimmen. Liefert kategorisierte Einträge ohne Wichtung,
  die nach Durchsicht und Korrekturen mit prepare_patch.py eingepflegt
  werden können.
